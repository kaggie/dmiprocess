{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRS Linear Combination Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fft\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch for MRS\n",
    "\n",
    "PyTorch can be a powerful tool for MRS analysis due to its extensive tensor operations and automatic differentiation capabilities. Here are some functionalities relevant to spectral analysis and LCM fitting:\n",
    "\n",
    "- **`torch.fft.fft`**: For performing Fast Fourier Transform, essential for converting time-domain MRS signals to the frequency domain.\n",
    "- **`torch.fft.ifft`**: For performing Inverse Fast Fourier Transform, to go back from frequency-domain to time-domain.\n",
    "- **`torch.linalg.lstsq`**: Useful for solving linear systems of equations, which is the core of Linear Combination Modeling (LCM). This function can find the least-squares solution to `AX = B`, where `A` would be the matrix of basis spectra and `B` would be the measured MRS data.\n",
    "- **`torch.linalg.solve`**: Can also be used for solving linear systems if the matrix `A` is square and invertible. For LCM, `lstsq` is generally more appropriate as the system is often overdetermined.\n",
    "- **Tensor Operations**: General tensor operations for manipulating data, such as slicing, reshaping, and element-wise arithmetic, will be heavily used for preprocessing and handling spectra.\n",
    "- **Autograd (`torch.autograd`)**: While not immediately used for basic LCM, PyTorch's automatic differentiation could be invaluable for more advanced modeling, such as fitting non-linear parameters or incorporating regularization with learnable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup LCM Library Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the lcm_library is in the Python path\n",
    "# This is needed if running from the notebooks directory directly\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..')) # Assuming notebooks is one level down from mrs_lcm_analysis\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "print(f\"Added {module_path} to sys.path\")\n",
    "\n",
    "# Now we can import from lcm_library\n",
    "from lcm_library.basis import BasisSpectrum, BasisSet\n",
    "from lcm_library.data_loading import MRSData \n",
    "from lcm_library.model import LinearCombinationModel \n",
    "from lcm_library.baseline import create_polynomial_basis_vectors, generate_polynomial_baseline \n",
    "from scipy.signal.windows import gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basis Set Management\n",
    "\n",
    "The `BasisSpectrum` and `BasisSet` classes help manage the individual metabolite spectra that will be used for LCM fitting. These are frequency-domain representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define consistent parameters for spectra generation\n",
    "N_POINTS = 1024          # Number of points in the spectrum\n",
    "SW_HZ = 2000.0           # Sampling frequency / Spectral Width in Hz\n",
    "CFREQ_MHZ = 123.2        # Central frequency in MHz (e.g., for 3T proton MRS)\n",
    "\n",
    "hz_axis_full = np.linspace(-SW_HZ / 2, SW_HZ / 2 - SW_HZ / N_POINTS, N_POINTS)\n",
    "ppm_axis_basis = (hz_axis_full / CFREQ_MHZ)[::-1] \n",
    "\n",
    "def create_metabolite_basis(name, center_ppm, width_ppm, amplitude=1.0):\n",
    "    gauss_std_hz = (width_ppm * CFREQ_MHZ) / (2 * np.sqrt(2 * np.log(2))) \n",
    "    gauss_std_points = (gauss_std_hz / SW_HZ) * N_POINTS\n",
    "    spectrum_data_unsh = gaussian(N_POINTS, std=gauss_std_points) * amplitude\n",
    "    ppm_axis_natural = (hz_axis_full / CFREQ_MHZ)\n",
    "    peak_idx_natural = np.argmin(np.abs(ppm_axis_natural - center_ppm))\n",
    "    spectrum_data_unsh = np.roll(spectrum_data_unsh, peak_idx_natural - N_POINTS // 2) \n",
    "    spectrum_data_shifted = np.fft.fftshift(spectrum_data_unsh) \n",
    "    return BasisSpectrum(name=name, spectrum_data=spectrum_data_shifted, frequency_axis=ppm_axis_basis)\n",
    "\n",
    "naa_basis = create_metabolite_basis(name=\"NAA\", center_ppm=2.01, width_ppm=0.05)\n",
    "cr_basis = create_metabolite_basis(name=\"Cr\", center_ppm=3.03, width_ppm=0.05)\n",
    "cho_basis = create_metabolite_basis(name=\"Cho\", center_ppm=3.22, width_ppm=0.05)\n",
    "\n",
    "naa_basis.plot()\n",
    "plt.title(\"NAA-like Basis Spectrum Example (Shifted Data)\")\n",
    "plt.xlim(max(ppm_axis_basis), min(ppm_axis_basis)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_set_lcm = BasisSet()\n",
    "basis_set_lcm.add_metabolite(naa_basis)\n",
    "basis_set_lcm.add_metabolite(cr_basis)\n",
    "basis_set_lcm.add_metabolite(cho_basis)\n",
    "print(f\"Metabolites in basis set for LCM: {basis_set_lcm.get_metabolite_names()}\")\n",
    "basis_matrix_lcm = basis_set_lcm.get_basis_matrix() \n",
    "print(f\"Shape of the basis matrix for LCM: {basis_matrix_lcm.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRS Data Loading and Processing (Brief recap, then new data for fitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Simulated MRS Data for Fitting (Frequency Domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_amplitudes = {\n",
    "    \"NAA\": 10.0,\n",
    "    \"Cr\": 8.0,\n",
    "    \"Cho\": 5.0\n",
    "}\n",
    "\n",
    "metabolite_order = basis_set_lcm.get_metabolite_names()\n",
    "true_amplitudes_array = np.array([true_amplitudes[name] for name in metabolite_order])\n",
    "\n",
    "ideal_spectrum_shifted = basis_matrix_lcm @ true_amplitudes_array\n",
    "\n",
    "noise_std = 0.5 \n",
    "noise = np.random.normal(0, noise_std, size=ideal_spectrum_shifted.shape)\n",
    "simulated_mrs_spectrum_shifted = ideal_spectrum_shifted + noise\n",
    "\n",
    "mrs_data_for_fitting_freq = MRSData(data_array=simulated_mrs_spectrum_shifted.astype(np.complex64), \n",
    "                                   data_type=\"frequency\", \n",
    "                                   central_frequency=CFREQ_MHZ, \n",
    "                                   sampling_frequency=SW_HZ,\n",
    "                                   metadata={'name': 'Simulated Spectrum for LCM (Freq Domain)', 'ppm_unit':'ppm'})\n",
    "\n",
    "print(mrs_data_for_fitting_freq)\n",
    "mrs_data_for_fitting_freq.plot(unit='ppm')\n",
    "plt.title(\"Simulated MRS Spectrum for Fitting (Freq Domain, Shifted)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Combination Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Frequency Domain Fitting\n",
    "\n",
    "The following examples demonstrate fitting using the `LinearCombinationModel`. The MRS data to be fitted is explicitly in the frequency domain (having been simulated or converted). The basis set provided to the model is also composed of frequency-domain spectra. The fitting process itself operates on these frequency spectra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fitting the Full Spectrum Range (Numpy) - No Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcm_model_freq_numpy = LinearCombinationModel(mrs_data=mrs_data_for_fitting_freq, basis_set=basis_set_lcm)\n",
    "lcm_model_freq_numpy.fit(use_torch=False) \n",
    "\n",
    "estimated_amps_freq_numpy = lcm_model_freq_numpy.get_estimated_metabolite_amplitudes()\n",
    "print(\"Estimated Amplitudes (Freq Domain, NumPy fit, No Baseline):\")\n",
    "for name, amp in estimated_amps_freq_numpy.items():\n",
    "    print(f\"  {name}: {amp:.2f} (True: {true_amplitudes.get(name, 'N/A')})\")\n",
    "\n",
    "lcm_model_freq_numpy.plot_fit(plot_individual_components=True, xlim_ppm=(max(ppm_axis_basis), min(ppm_axis_basis)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fitting with a Specific PPM Range (PyTorch) - No Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FITTING_RANGE_PPM = (1.8, 3.5) \n",
    "\n",
    "lcm_model_freq_torch_ranged = LinearCombinationModel(mrs_data=mrs_data_for_fitting_freq, \n",
    "                                                 basis_set=basis_set_lcm, \n",
    "                                                 fitting_range_ppm=FITTING_RANGE_PPM)\n",
    "lcm_model_freq_torch_ranged.fit(use_torch=True) \n",
    "\n",
    "estimated_amps_freq_torch_ranged = lcm_model_freq_torch_ranged.get_estimated_metabolite_amplitudes()\n",
    "print(f\"Estimated Amplitudes (Freq Domain, PyTorch fit, range {FITTING_RANGE_PPM} ppm, No Baseline):\")\n",
    "for name, amp in estimated_amps_freq_torch_ranged.items():\n",
    "    print(f\"  {name}: {amp:.2f} (True: {true_amplitudes.get(name, 'N/A')})\")\n",
    "\n",
    "lcm_model_freq_torch_ranged.plot_fit(plot_individual_components=True, xlim_ppm=(max(ppm_axis_basis), min(ppm_axis_basis)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Amplitudes (Frequency Domain Fitting - No Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Amplitudes:\")\n",
    "for name, amp in true_amplitudes.items():\n",
    "    print(f\"  {name}: {amp}\")\n",
    "\n",
    "print(\"\\nEstimated Amplitudes (Freq Domain, NumPy, full range, No Baseline):\")\n",
    "for name, amp in estimated_amps_freq_numpy.items():\n",
    "    print(f\"  {name}: {amp:.2f}\")\n",
    "\n",
    "print(\"\\nEstimated Amplitudes (Freq Domain, PyTorch, ranged, No Baseline):\")\n",
    "for name, amp in estimated_amps_freq_torch_ranged.items():\n",
    "    print(f\"  {name}: {amp:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Domain Fitting\n",
    "\n",
    "The `LinearCombinationModel` can also handle time-domain MRS data as input. It achieves this by internally converting the time-domain signal (FID) to the frequency domain using an FFT, and then performing the fit against the frequency-domain basis set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Fitting Time-Domain Data via Frequency Domain Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Time-Domain MRSData (Simulated FID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_matrix_unsh = scipy.fft.ifftshift(basis_matrix_lcm, axes=0)\n",
    "basis_fids_matrix = scipy.fft.ifft(basis_matrix_unsh, axis=0)\n",
    "ideal_fid = basis_fids_matrix @ true_amplitudes_array\n",
    "\n",
    "time_noise_std = 0.02 \n",
    "time_noise = time_noise_std * (np.random.randn(N_POINTS) + 1j * np.random.randn(N_POINTS))\n",
    "simulated_fid_with_noise = ideal_fid + time_noise\n",
    "\n",
    "mrs_data_for_fitting_time = MRSData(data_array=simulated_fid_with_noise.astype(np.complex64),\n",
    "                                    data_type=\"time\",\n",
    "                                    sampling_frequency=SW_HZ,\n",
    "                                    central_frequency=CFREQ_MHZ,\n",
    "                                    metadata={'name': 'Simulated FID for LCM', 'ppm_unit':'ppm'})\n",
    "\n",
    "print(mrs_data_for_fitting_time)\n",
    "mrs_data_for_fitting_time.plot() \n",
    "plt.title(\"Simulated Time-Domain MRS Data (FID) for Fitting\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit with LinearCombinationModel (No Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcm_model_time_input = LinearCombinationModel(mrs_data=mrs_data_for_fitting_time, \n",
    "                                            basis_set=basis_set_lcm)\n",
    "lcm_model_time_input.fit(use_torch=False) \n",
    "\n",
    "estimated_amps_time_input = lcm_model_time_input.get_estimated_metabolite_amplitudes()\n",
    "print(\"Estimated Amplitudes (Time-Domain Input, NumPy fit, No Baseline):\")\n",
    "for name, amp in estimated_amps_time_input.items():\n",
    "    print(f\"  {name}: {amp:.2f} (True: {true_amplitudes.get(name, 'N/A')})\")\n",
    "\n",
    "lcm_model_time_input.plot_fit(plot_individual_components=True, xlim_ppm=(max(ppm_axis_basis), min(ppm_axis_basis)))\n",
    "plt.suptitle(\"Fit Result for Time-Domain Input (Converted to Frequency Domain, No Baseline)\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates that the `LinearCombinationModel` can accept time-domain `MRSData`. The model internally converts this to the frequency domain before fitting against the (frequency-domain) basis set. The resulting amplitudes are comparable to those obtained from fitting frequency-domain data directly, with minor differences potentially arising from FFT/iFFT numerical precision and the different noise characteristics applied in time vs. frequency domains in these simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Direct Time Domain Fitting (Conceptual Outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different approach to fitting time-domain MRS data is to perform the linear combination directly in the time domain. This requires a basis set composed of time-domain signals (FIDs) rather than frequency-domain spectra.\n",
    "\n",
    "**Concept**: The acquired time-domain signal (FID) $D_{\\text{time}}$ is modeled as a linear combination of time-domain basis signals $B_{\\text{time},j}$ for each metabolite $j$:\n",
    "\n",
    "$$ D_{\\text{time}}(t) = \\sum_{j} A_j \\cdot B_{\\text{time},j}(t) + \\epsilon(t) $$\n",
    "\n",
    "where $A_j$ are the amplitudes to be estimated.\n",
    "\n",
    "**Basis Set**: This would require a `BasisSet` (or a similar structure) where each entry is a time-domain FID for a metabolite. These basis FIDs must be sampled at the same rate and have the same number of points as the MRS data being analyzed.\n",
    "\n",
    "**Fitting Equation**: The problem can be cast into a matrix form $D_{\\text{time}} = B_{\\text{time}} \\cdot A$, where $D_{\\text{time}}$ is a vector of the acquired FID data points, $B_{\\text{time}}$ is a matrix whose columns are the basis FIDs, and $A$ is the vector of amplitudes. This can be solved using linear least squares.\n",
    "\n",
    "**Implementation Sketch (Conceptual)**:\n",
    "```python\n",
    "# Conceptual Python code for direct time-domain fitting\n",
    "# mrs_data_object: An MRSData instance containing the time-domain signal\n",
    "# time_domain_basis_set: An object managing time-domain basis FIDs\n",
    "\n",
    "# acquired_fid = mrs_data_object.get_time_domain_data()\n",
    "# time_domain_basis_matrix = time_domain_basis_set.get_basis_matrix() # Each column is a basis FID\n",
    "\n",
    "# amplitudes, _, _, _ = np.linalg.lstsq(time_domain_basis_matrix, acquired_fid, rcond=None)\n",
    "```\n",
    "\n",
    "**Advantages (Potential)**:\n",
    "- Avoids potential artifacts or information loss from Fast Fourier Transform (FFT) if all processing is kept in the time domain.\n",
    "- Might be more intuitive for certain types of signal processing or artifact correction applied in the time domain.\n",
    "\n",
    "**Complexities**:\n",
    "- **Sensitivity to Phase and Frequency Errors**: Small misalignments in starting phase or exact resonant frequencies between the acquired data FID and the basis FIDs can lead to significant fitting errors. These parameters often need to be explicitly modeled and optimized for each metabolite, making the problem non-linear.\n",
    "- **Linewidth Consistency**: The linewidth (decay rate, $T_2^*$) of each basis FID must match that in the acquired data, or the linewidth itself needs to be part of the fitting process (again, non-linear).\n",
    "- **Baseline Modeling**: Broad, slowly varying baseline signals are more challenging to model directly in the time domain compared to the frequency domain where they often appear as smooth curves.\n",
    "- **Computational Cost**: If non-linear optimization is involved for phase, frequency, or linewidth, the computational cost can be significantly higher.\n",
    "\n",
    "**Comparison to Conversion Approach**: Direct time-domain fitting is fundamentally different from the conversion approach used by our current `LinearCombinationModel`. The conversion approach transforms the problem into the frequency domain, where phase issues are often simpler (e.g., zero-order phase correction) and spectral lineshapes are more directly comparable. Most robust and widely used time-domain fitting methods (e.g., AMARES, AQSES, QUEST) are more complex than a simple linear least-squares fit; they typically involve non-linear optimization algorithms to determine not only amplitudes but also frequencies, phases, and damping factors for each component in the time domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with Baseline Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's demonstrate fitting a spectrum that includes a polynomial baseline. We will use the `baseline_degree` parameter in `LinearCombinationModel`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simulate MRS Data with a Known Polynomial Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_plot_range_ppm = (0.5, 4.2) \n",
    "baseline_calc_indices = np.where((ppm_axis_basis >= fit_plot_range_ppm[0]) & (ppm_axis_basis <= fit_plot_range_ppm[1]))[0]\n",
    "ppm_axis_for_baseline_calc = ppm_axis_basis[baseline_calc_indices]\n",
    "\n",
    "ppm_min_bl = ppm_axis_for_baseline_calc.min()\n",
    "ppm_max_bl = ppm_axis_for_baseline_calc.max()\n",
    "ppm_axis_for_baseline_calc_norm = 2 * (ppm_axis_for_baseline_calc - ppm_min_bl) / (ppm_max_bl - ppm_min_bl) - 1\n",
    "\n",
    "true_baseline_coeffs = np.array([7.0, -2.5, 1.5]) \n",
    "true_baseline_degree = len(true_baseline_coeffs) - 1\n",
    "\n",
    "true_baseline_segment = generate_polynomial_baseline(ppm_axis_for_baseline_calc_norm, true_baseline_coeffs)\n",
    "\n",
    "true_baseline_full = np.zeros_like(ppm_axis_basis)\n",
    "true_baseline_full[baseline_calc_indices] = true_baseline_segment\n",
    "\n",
    "metabolite_signal_for_bl_sim = ideal_spectrum_shifted\n",
    "\n",
    "simulated_mrs_with_baseline_shifted = metabolite_signal_for_bl_sim + true_baseline_full\n",
    "\n",
    "noise_std_bl = 0.7 \n",
    "noise_bl = np.random.normal(0, noise_std_bl, size=simulated_mrs_with_baseline_shifted.shape)\n",
    "simulated_mrs_with_baseline_noisy_shifted = simulated_mrs_with_baseline_shifted + noise_bl\n",
    "\n",
    "mrs_data_with_baseline = MRSData(data_array=simulated_mrs_with_baseline_noisy_shifted.astype(np.complex64),\n",
    "                                 data_type=\"frequency\",\n",
    "                                 central_frequency=CFREQ_MHZ,\n",
    "                                 sampling_frequency=SW_HZ,\n",
    "                                 metadata={'name': 'Simulated Spectrum with Baseline', 'ppm_unit':'ppm'})\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(ppm_axis_basis, mrs_data_with_baseline.data_array.real, label='Simulated Spectrum with Baseline + Noise')\n",
    "plt.plot(ppm_axis_basis, metabolite_signal_for_bl_sim, label='Metabolite Signal Component', linestyle='--')\n",
    "plt.plot(ppm_axis_basis, true_baseline_full, label='True Baseline Component', linestyle=':')\n",
    "plt.xlim(max(fit_plot_range_ppm), min(fit_plot_range_ppm)) \n",
    "plt.xlabel('Frequency (ppm)')\n",
    "plt.ylabel('Intensity')\n",
    "plt.title('Simulated MRS Data with Baseline')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fit with LinearCombinationModel including Baseline Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_FIT_DEGREE = 2 \n",
    "FITTING_RANGE_FOR_BASELINE_PPM = (0.5, 4.0) \n",
    "\n",
    "lcm_model_with_baseline = LinearCombinationModel(\n",
    "    mrs_data=mrs_data_with_baseline,\n",
    "    basis_set=basis_set_lcm,\n",
    "    fitting_range_ppm=FITTING_RANGE_FOR_BASELINE_PPM,\n",
    "    baseline_degree=BASELINE_FIT_DEGREE\n",
    ")\n",
    "\n",
    "lcm_model_with_baseline.fit(use_torch=False) \n",
    "\n",
    "estimated_met_amps_bl = lcm_model_with_baseline.get_estimated_metabolite_amplitudes()\n",
    "print(f\"Estimated Metabolite Amplitudes (with baseline degree {BASELINE_FIT_DEGREE}):\")\n",
    "for name, amp in estimated_met_amps_bl.items():\n",
    "    print(f\"  {name}: {amp:.2f} (True: {true_amplitudes.get(name, 'N/A')})\")\n",
    "\n",
    "estimated_bl_coeffs = lcm_model_with_baseline.get_estimated_baseline_amplitudes()\n",
    "print(f\"\\nEstimated Baseline Coefficients (degree {BASELINE_FIT_DEGREE}): {np.array2string(estimated_bl_coeffs, formatter={'float_kind':lambda x: '%.2f' % x})}\")\n",
    "print(f\"True Baseline Coefficients (degree {true_baseline_degree}): {np.array2string(true_baseline_coeffs, formatter={'float_kind':lambda x: '%.2f' % x})}\")\n",
    "\n",
    "lcm_model_with_baseline.plot_fit(plot_individual_components=True, xlim_ppm=(max(fit_plot_range_ppm),min(fit_plot_range_ppm)))\n",
    "plt.suptitle(f\"Fit with Baseline Correction (Degree {BASELINE_FIT_DEGREE})\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compare True vs. Fitted Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_baseline_component = lcm_model_with_baseline.get_fitted_baseline()\n",
    "freq_axis_fitted_range = lcm_model_with_baseline.frequency_axis_to_fit\n",
    "\n",
    "true_baseline_on_fitted_axis = np.interp(freq_axis_fitted_range, ppm_axis_basis[::-1], true_baseline_full[::-1])[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(freq_axis_fitted_range, true_baseline_on_fitted_axis, label='True Baseline (on fitted range)', linestyle='--', color='blue')\n",
    "plt.plot(freq_axis_fitted_range, fitted_baseline_component, label=f'Fitted Baseline (degree {BASELINE_FIT_DEGREE})', linestyle='-', color='red')\n",
    "plt.xlabel(f\"Frequency ({mrs_data_with_baseline.metadata.get('ppm_unit', 'ppm')})\")\n",
    "plt.ylabel('Intensity')\n",
    "plt.title('Comparison of True Baseline vs. Fitted Baseline Component')\n",
    "plt.xlim(max(freq_axis_fitted_range), min(freq_axis_fitted_range)) \n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "rmsd_baseline = np.sqrt(np.mean((true_baseline_on_fitted_axis - fitted_baseline_component)**2))\n",
    "print(f\"RMSD between true and fitted baseline: {rmsd_baseline:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Quantification\n",
    "\n",
    "Relative quantification expresses the amount of a metabolite relative to another, typically a stable reference metabolite like Creatine (Cr) or total Creatine (Cr + PCr). The estimated amplitudes from the LCM fit are used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model with baseline correction for this example\n",
    "reference_metabolites = ['Cr'] # Using Cr as the reference\n",
    "relative_quantifications = lcm_model_with_baseline.get_relative_quantification(reference_metabolites)\n",
    "\n",
    "if relative_quantifications:\n",
    "    print(f\"Relative Quantifications (referenced to {', '.join(reference_metabolites)}):\")\n",
    "    for metab, rel_amp in relative_quantifications.items():\n",
    "        print(f\"  {metab}/{'/'.join(reference_metabolites)}: {rel_amp:.2f}\")\n",
    "else:\n",
    "    print(\"Could not calculate relative quantifications.\")\n",
    "\n",
    "# Example of how true relative concentrations would be:\n",
    "if true_amplitudes.get('Cr', 0) > 0:\n",
    "    print(\"\\nTrue Relative Ratios (to Cr):\")\n",
    "    for metab, true_amp in true_amplitudes.items():\n",
    "        print(f\"  {metab}/Cr: {true_amp / true_amplitudes['Cr']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values above show, for instance, 'NAA/Cr' which is the ratio of the estimated NAA amplitude to the estimated Cr amplitude. These ratios can be useful for comparing metabolic profiles across different datasets or conditions, as they can be less sensitive to variations in overall signal intensity (e.g., due to coil loading or voxel size) than absolute amplitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute Quantification (Conceptual Outline)\n",
    "\n",
    "Absolute quantification aims to determine the actual molar concentration of metabolites within the MRS voxel (e.g., in mmol/L or institutional units). This is a much more complex task than relative quantification and typically requires additional information and calibration steps.\n",
    "\n",
    "**Common Approaches**:\n",
    "1.  **Internal Water Reference**: Uses the unsuppressed water signal from the same voxel as an internal concentration reference. Requires acquiring a water reference scan.\n",
    "2.  **External Reference Phantom**: Uses a phantom with a known concentration of a reference substance, scanned under similar conditions.\n",
    "\n",
    "**Key Requirements and Complexities (especially for Internal Water Referencing)**:\n",
    "-   **Water Signal Acquisition**: An unsuppressed water signal must be acquired from the same voxel.\n",
    "-   **Water Amplitude Estimation**: The amplitude of this water signal needs to be accurately estimated, often by fitting it with a lineshape model.\n",
    "-   **Proton Counts**: Knowledge of the number of protons contributing to the metabolite signal (e.g., NAA methyl group has 3 protons) and the water signal (2 protons) is needed.\n",
    "-   **Relaxation Corrections**: Differences in $T_1$ and $T_2$ relaxation times between water and metabolites, and between different metabolites, must be accounted for. This requires knowledge or estimation of these relaxation times for the specific acquisition parameters (TR, TE).\n",
    "-   **Tissue Correction**: The contribution of different tissue types within the voxel (e.g., gray matter, white matter, CSF) needs to be considered, as water content and relaxation times vary between tissues. This often involves image segmentation.\n",
    "-   **Coil Loading and System Gains**: Variations in coil loading and system gains need to be stable or corrected for.\n",
    "-   **Water Concentration**: Assumed concentration of water in tissue (e.g., for brain tissue, around 35-45 M depending on tissue composition).\n",
    "\n",
    "**Simplified Formula (Illustrative - Omits Many Corrections)**:\n",
    "A highly simplified formula for absolute concentration of a metabolite (Met) using an internal water reference (Wat) might look like:\n",
    "\n",
    "$$ [\\text{Met}] = \\frac{S_{\\text{Met}}}{N_{\\text{H,Met}}} \\cdot \\frac{N_{\\text{H,Wat}}}{S_{\\text{Wat}}} \\cdot [\\text{Wat}]_{\\text{ref}} \\cdot C_{\\text{relax}} \\cdot C_{\\text{tissue}} \\dots $$\n",
    "\n",
    "Where:\n",
    "-   $S_{\\text{Met}}$ and $S_{\\text{Wat}}$ are the estimated signal amplitudes (from LCM for Met, from water fit for Wat).\n",
    "-   $N_{\\text{H,Met}}$ and $N_{\\text{H,Wat}}$ are the number of protons per molecule for the metabolite and water, respectively.\n",
    "-   $[\\text{Wat}]_{\\text{ref}}$ is the reference concentration of water in the tissue.\n",
    "-   $C_{\\text{relax}}$ represents all relaxation corrections.\n",
    "-   $C_{\\text{tissue}}$ represents tissue composition corrections.\n",
    "\n",
    "**Implementation in this Library (Conceptual)**:\n",
    "Full absolute quantification is beyond the current scope of this introductory library. However, a conceptual sketch might involve:\n",
    "\n",
    "```python\n",
    "# Conceptual: MRSData might need a method to get water amplitude\n",
    "# class MRSData:\n",
    "#     ...\n",
    "#     def get_water_amplitude(self, water_ref_data_array):\n",
    "#         # Fit water_ref_data_array (e.g. with a Lorentzian)\n",
    "#         # Return estimated water amplitude\n",
    "#         pass\n",
    "\n",
    "# Conceptual: LinearCombinationModel might have a method like this\n",
    "# class LinearCombinationModel:\n",
    "#     ...\n",
    "#     def get_absolute_quantification_simplified(self, water_amplitude, water_conc_ref=35880, protons_metabolite_map=None):\n",
    "#         if self.estimated_metabolite_amplitudes is None or water_amplitude <= 0:\n",
    "#             return None\n",
    "#         if protons_metabolite_map is None:\n",
    "#             # Example: protons_metabolite_map = {'NAA': 3, 'Cr': 3, 'Cho': 9} (for methyl/CH2 groups often used)\n",
    "#             print(\"Warning: protons_metabolite_map not provided. Using defaults or failing.\")\n",
    "#             return None # Or use some defaults\n",
    "#         \n",
    "#         protons_water = 2\n",
    "#         abs_concentrations = {}\n",
    "#         for metab_name, metab_amp in self.estimated_metabolite_amplitudes.items():\n",
    "#             n_h_metab = protons_metabolite_map.get(metab_name)\n",
    "#             if n_h_metab is None:\n",
    "#                 abs_concentrations[metab_name] = None # Or skip\n",
    "#                 continue\n",
    "#             # Extremely simplified: S_met / N_H_met * N_H_wat / S_wat * [Wat_ref]\n",
    "#             # This ignores ALL relaxation and tissue corrections.\n",
    "#             abs_conc = (metab_amp / n_h_metab) * (protons_water / water_amplitude) * water_conc_ref\n",
    "#             abs_concentrations[metab_name] = abs_conc\n",
    "#         return abs_concentrations\n",
    "```\n",
    "**Note**: The actual implementation of absolute quantification is highly complex and requires careful handling of many experimental and physiological factors. The sketch above is purely illustrative of the basic principle using estimated signal amplitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Estimation: Cramer-Rao Lower Bounds (CRLBs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model with baseline correction for this example, as it's more complete\n",
    "crlbs_info = lcm_model_with_baseline.get_estimated_crlbs()\n",
    "\n",
    "if crlbs_info and crlbs_info['absolute'] is not None and crlbs_info['percent_metabolite'] is not None:\n",
    "    print(\"Estimated Amplitudes and CRLBs (from model with baseline):\")\n",
    "    \n",
    "    # Metabolite CRLBs\n",
    "    for name, amp in lcm_model_with_baseline.get_estimated_metabolite_amplitudes().items():\n",
    "        abs_crlb = crlbs_info['absolute'].get(name, float('nan'))\n",
    "        pct_crlb = crlbs_info['percent_metabolite'].get(name, float('nan'))\n",
    "        print(f\"  {name}: Amplitude = {amp:.2f} \u00B1 {abs_crlb:.2f} (CRLB {pct_crlb:.2f}%)\")\n",
    "    \n",
    "    # Baseline CRLBs (absolute only)\n",
    "    if lcm_model_with_baseline.estimated_baseline_amplitudes is not None:\n",
    "        print(\"\\n  Baseline Parameter CRLBs (Absolute):\")\n",
    "        for i, b_amp in enumerate(lcm_model_with_baseline.estimated_baseline_amplitudes):\n",
    "            bl_param_name = f\"baseline_deg{i}\"\n",
    "            abs_crlb = crlbs_info['absolute'].get(bl_param_name, float('nan'))\n",
    "            print(f\"    {bl_param_name}: Coeff = {b_amp:.2f} \u00B1 {abs_crlb:.2f}\")\n",
    "else:\n",
    "    print(\"Could not retrieve CRLB information or it was not calculated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRLBs represent the theoretical minimum variance (or standard deviation) for an unbiased estimator. A lower CRLB percentage for a metabolite indicates a more reliable and precise estimation of its amplitude. High CRLB values (e.g., > 20-30%) often suggest that the metabolite's quantification is unreliable, possibly due to low SNR, strong overlap with other signals, or instability in the model fit.\n",
    "\n",
    "Factors affecting CRLBs include:\n",
    "- **Signal-to-Noise Ratio (SNR)**: Higher SNR generally leads to lower CRLBs.\n",
    "- **Number of Data Points vs. Parameters**: More data points relative to the number of fitted parameters can improve CRLB estimates.\n",
    "- **Model Appropriateness**: If the model (basis set, baseline) does not accurately reflect the data, CRLBs may not be meaningful.\n",
    "- **Collinearity in Basis Set**: Highly similar (collinear) basis spectra can lead to unstable amplitude estimates and high CRLBs for the involved metabolites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating Prior Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit Prior Knowledge via Basis Sets\n",
    "\n",
    "The primary way prior knowledge is incorporated into the current `LinearCombinationModel` is through the **basis set**. Each `BasisSpectrum` within the `BasisSet` represents a known spectral pattern for a specific metabolite under defined experimental conditions (e.g., field strength, echo time, pulse sequence). This includes:\n",
    "-   **Chemical Shifts**: The resonant frequencies of different proton groups within the metabolite.\n",
    "-   **J-Coupling Patterns**: The splitting of peaks due to interactions between nuclear spins.\n",
    "-   **Relative Intensities**: The expected relative heights of peaks within a single metabolite's spectrum.\n",
    "-   **Lineshape**: The inherent shape of the peaks, often modeled as Lorentzian or Gaussian, or a combination (Voigt).\n",
    "\n",
    "By providing these pre-defined spectral shapes, we are implicitly constraining the model to find combinations of these known patterns. The model assumes these patterns are fixed and only solves for their amplitudes (and a smooth baseline if requested)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit Prior Knowledge and Constraints (Conceptual)\n",
    "\n",
    "More advanced LCM implementations often allow for the incorporation of **explicit prior knowledge** or **constraints** on the fitting parameters. This can help stabilize the fit, especially for noisy data or highly overlapping signals. These are not implemented in the current simple model but are important concepts:\n",
    "\n",
    "1.  **Soft Constraints on Amplitudes**:\n",
    "    *   **Physiological Ratios**: Known physiological ratios between certain metabolites can be incorporated as soft constraints (e.g., the sum of Glutamate (Glu) and Glutamine (Gln) might be constrained relative to Creatine (Cr)).\n",
    "    *   **Non-Negativity**: Metabolite amplitudes are often constrained to be non-negative, though this is not always strictly true for all fitting approaches or if the basis set is imperfect.\n",
    "    *   **Implementation**: Often achieved by adding penalty terms to the least-squares objective function or using Bayesian priors.\n",
    "\n",
    "2.  **Constraints on Peak Parameters (Non-Linear Aspects)**:\n",
    "    *   **Frequency Shifts**: Small, constrained frequency shifts can be allowed for all metabolites together (global B0 shift) or for individual metabolites to account for minor field drifts or susceptibility effects. This makes the model non-linear.\n",
    "    *   **Linewidth Broadening**: A common Gaussian or Lorentzian broadening factor can be applied to all basis spectra to match the observed linewidth in the data, or individual broadening factors can be used. This also introduces non-linearity.\n",
    "    *   **Phase Correction**: Minor zero-order or first-order phase corrections can be part of the fitting process.\n",
    "\n",
    "3.  **Mathematical Formulation**:\n",
    "    *   Incorporating these non-linear parameters typically requires moving from a simple linear least-squares solution (`np.linalg.lstsq`) to non-linear optimization algorithms (e.g., Levenberg-Marquardt).\n",
    "    *   Penalty terms or Bayesian priors modify the objective function being minimized.\n",
    "\n",
    "4.  **Benefit**:\n",
    "    *   Can significantly improve the robustness and reliability of quantification, especially for low signal-to-noise ratio (SNR) metabolites or when peaks heavily overlap.\n",
    "\n",
    "Established tools like LCModel and its variants incorporate many such forms of prior knowledge and constraints to achieve their robust performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12" 
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

[end of mrs_lcm_analysis/notebooks/01_Initial_Setup_and_Examples.ipynb]

[end of mrs_lcm_analysis/notebooks/01_Initial_Setup_and_Examples.ipynb]

[end of mrs_lcm_analysis/notebooks/01_Initial_Setup_and_Examples.ipynb]

[end of mrs_lcm_analysis/notebooks/01_Initial_Setup_and_Examples.ipynb]
